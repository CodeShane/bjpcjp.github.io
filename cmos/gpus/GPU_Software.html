<?xml version="1.0" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>GPU Software</title>
<style type="text/css">
         body {
  font-family: 'Roboto Condensed','Droid Sans',arial,sans-serif;
  font-size: 15px;
  color: rgba(0,0,0,0.8);
  word-wrap: break-word;
  background-color: #e8e8e8;
}

hr {
    display: block;
    margin-top: 10px;
    margin-bottom: 10px;
    margin-left: 5px;
    margin-right: 5px;
    border-style: inset dashed;
    border-width: 1px;
}

.note {
  outline: none;
  box-shadow: 0 2px 1px rgba(0,0,0,0.08);
  box-sizing: border-box;

  max-width: 600px;
  min-width: 240px;
  margin: 20px;

  background-color: rgb(255, 255, 255);
}

.note .heading {
  font-size: 12px;
  padding: 15px 15px 0 15px;
  color: rgba(100,100,100,0.8);
}

.note .title {
  font-size: 17px;
  font-weight: bold;
  padding: 15px 15px 0 15px;
  min-height: 28px;
}

.note .content {
  padding: 12px 15px 15px 15px;
  font-family: 'Roboto Slab','Times New Roman',serif;
  font-size: 14px;
}

.note .attachments {
  padding: 0 15px 15px 15px;
}

.attachments ul {
  padding: 0;
  margin: 0;
}

.attachments li {
  list-style-type: none;
  margin-top: 12px;
}

.attachments li img {
  max-width: 100%;
}

.attachments .audio {
  background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAxOC4wLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4KPCFET0NUWVBFIHN2ZyAgUFVCTElDICctLy9XM0MvL0RURCBTVkcgMS4xLy9FTicgICdodHRwOi8vd3d3LnczLm9yZy9HcmFwaGljcy9TVkcvMS4xL0RURC9zdmcxMS5kdGQnPgo8c3ZnIGlkPSJMYXllcl8xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbDpzcGFjZT0icHJlc2VydmUiIHZpZXdCb3g9IjAgMCAyMCAyMCIgdmVyc2lvbj0iMS4xIiB5PSIwcHgiIHg9IjBweCIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDIwIDIwIj4KPHBhdGggZD0ibTEgN3Y2aDRsNSA1di0xNmwtNSA1aC00em0xMy41IDNjMC0xLjgtMS0zLjMtMi41LTR2OGMxLjUtMC43IDIuNS0yLjIgMi41LTR6bS0yLjUtOC44djIuMWMyLjkgMC45IDUgMy41IDUgNi43cy0yLjEgNS44LTUgNi43djIuMWM0LTAuOSA3LTQuNSA3LTguOHMtMy03LjktNy04Ljh6Ii8+Cjwvc3ZnPgo=);
  background-size: 18px 18px;
  background-repeat: no-repeat;
  background-position: center;
  width: 22px;
  height: 22px;
  display: block;
}

.note .list {
  list-style: none;
  padding: 0;
  margin: 0;
}

.note .listitem {
}

.note .listitem .bullet {
  position: absolute;
}

.note .listitem .text {
  margin-left: 20px;
}

.note .identifier {
  color: rgba(0, 0, 0, 0.5);
}
.note .identifier:before {
  content: "(";
}
.note .identifier:after {
  content: ")";
}

/* Only show identifiers when the element is hovered. */
.note .listitem .identifier,
.note .chip .identifier {
  display: none;
}

.note .listitem:hover .identifier,
.note .chip:hover .identifier {
  display: inline;
}

.note .chips {
  padding: 12px 15px 15px 15px;
}

.note .chip {
  display: inline-block;
  max-width: 198px;
  margin: 2px 4px 2px 0;
  padding: 2px 5px;
  background: rgba(0, 0, 0, 0.1);
  border-radius: 2px;
  color: rgba(0, 0, 0, 0.7);
  font-size: 11px;
  font-family: 'Roboto','Droid Sans',arial,sans-serif;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.note .chip a {
  text-decoration: none;
  color: inherit;
}

.chip-icon {
  display: inline-block;
  width: 14px;
  height: 14px;
  background-size: 100%;
  margin-right: 5px;
  vertical-align: middle;
}

.annotation.ASSISTANT .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMjEuNSA2Yy0uODMgMC0xLjUuNjctMS41IDEuNVMyMC42NyA5IDIxLjUgOSAyMyA4LjMzIDIzIDcuNSAyMi4zMyA2IDIxLjUgNnpNMTcgMTRjMS42NiAwIDMtMS4zNCAzLTNzLTEuMzQtMy0zLTMtMyAxLjM0LTMgMyAxLjM0IDMgMyAzem0wIDFjLTEuOTMgMC0zLjUgMS41Ny0zLjUgMy41UzE1LjA3IDIyIDE3IDIyczMuNS0xLjU3IDMuNS0zLjVTMTguOTMgMTUgMTcgMTV6TTcgMkMzLjY5IDIgMSA0LjY5IDEgOHMyLjY5IDYgNiA2IDYtMi42OSA2LTYtMi42OS02LTYtNnoiLz4KICAgIDxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
}

.annotation.CALENDAR .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMTcgMTJoLTV2NWg1di01ek0xNiAxdjJIOFYxSDZ2Mkg1Yy0xLjExIDAtMS45OS45LTEuOTkgMkwzIDE5YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJoLTFWMWgtMnptMyAxOEg1VjhoMTR2MTF6Ii8+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+Cjwvc3ZnPgo=);
}

.annotation.DOCS .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+CiAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0yIC45LTIgMnYxNGMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6bS0xLjk5IDZIN1Y3aDEwLjAxdjJ6bTAgNEg3di0yaDEwLjAxdjJ6bS0zIDRIN3YtMmg3LjAxdjJ6Ii8+Cjwvc3ZnPgo=);
}

.annotation.GMAIL .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBmaWxsPSJub25lIiBkPSJNLTYxOC0yMTA0SDc4MnYzNjAwSC02MTh6TTAgMGgyNHYyNEgweiIvPgogICAgPHBhdGggZD0iTTIwIDRINGMtMS4xIDAtMiAuOS0yIDJ2MTJjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0wIDE0aC0yVjkuMkwxMiAxMyA2IDkuMlYxOEg0VjZoMS4ybDYuOCA0LjJMMTguOCA2SDIwdjEyeiIvPgo8L3N2Zz4K);
}

.annotation.SHEETS .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+CiAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0xLjk5LjktMS45OSAyTDMgOHYxMWMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6bTAgOGgtOHY4SDl2LThINVY5aDRWNWgydjRoOHYyeiIvPgo8L3N2Zz4K);
}

.annotation.SLIDES .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjRweCIgaGVpZ2h0PSIyNHB4IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+CiAgICA8cGF0aCBkPSJNMTkgM0g1Yy0xLjEgMC0xLjk5LjktMS45OSAydjE0YzAgMS4xLjg5IDIgMS45OSAyaDE0YzEuMSAwIDItLjkgMi0yVjVjMC0xLjEtLjktMi0yLTJ6bTAgMTNINVY4aDE0djh6Ii8+Cjwvc3ZnPgo=);
}

.annotation.WEBLINK .chip-icon {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMTkgNEg1Yy0xLjExIDAtMiAuOS0yIDJ2MTJjMCAxLjEuODkgMiAyIDJoMTRjMS4xIDAgMi0uOSAyLTJWNmMwLTEuMS0uODktMi0yLTJ6bTAgMTRINVY4aDE0djEweiIvPgogICAgPHBhdGggZmlsbD0ibm9uZSIgZD0iTTAgMGgyNHYyNEgweiIvPgo8L3N2Zz4K);
}

.sharees h2 {
  display: none;
}

.sharees ul {
  list-style: none;
  margin: 0;
  padding: 0 15px 15px 15px;
}

.sharees li {
  display: inline-block;
  width: 22px;
  height: 22px;
  text-indent: 100%;
  white-space: nowrap;
  overflow: hidden;
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMTIgMkM2LjQ4IDIgMiA2LjQ4IDIgMTJzNC40OCAxMCAxMCAxMCAxMC00LjQ4IDEwLTEwUzE3LjUyIDIgMTIgMnptMCAzYzEuNjYgMCAzIDEuMzQgMyAzcy0xLjM0IDMtMyAzLTMtMS4zNC0zLTMgMS4zNC0zIDMtM3ptMCAxNC4yYy0yLjUgMC00LjcxLTEuMjgtNi0zLjIyLjAzLTEuOTkgNC0zLjA4IDYtMy4wOCAxLjk5IDAgNS45NyAxLjA5IDYgMy4wOC0xLjI5IDEuOTQtMy41IDMuMjItNiAzLjIyeiIvPgogICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgo8L3N2Zz4K);
  background-size: 18px 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.sharees li.group {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNHB4IiBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzAwMDAwMCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+CiAgICA8cGF0aCBkPSJNMTYgMTFjMS42NiAwIDIuOTktMS4zNCAyLjk5LTNTMTcuNjYgNSAxNiA1Yy0xLjY2IDAtMyAxLjM0LTMgM3MxLjM0IDMgMyAzem0tOCAwYzEuNjYgMCAyLjk5LTEuMzQgMi45OS0zUzkuNjYgNSA4IDVDNi4zNCA1IDUgNi4zNCA1IDhzMS4zNCAzIDMgM3ptMCAyYy0yLjMzIDAtNyAxLjE3LTcgMy41VjE5aDE0di0yLjVjMC0yLjMzLTQuNjctMy41LTctMy41em04IDBjLS4yOSAwLS42Mi4wMi0uOTcuMDUgMS4xNi44NCAxLjk3IDEuOTcgMS45NyAzLjQ1VjE5aDZ2LTIuNWMwLTIuMzMtNC42Ny0zLjUtNy0zLjV6Ii8+Cjwvc3ZnPgo=);
}

.note .meta-icons {
  float: right;
}

.note .meta-icons span {
  display: inline-block;
  background-size: 18px 18px;
  background-repeat: no-repeat;
  background-position: center;
  width: 22px;
  height: 22px;
  padding-left: 4px;
}

.meta-icons .pinned {
  background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyMHB4IiBoZWlnaHQ9IjIwcHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0iIzQyODVmNCI+DQogICAgPHBhdGggZD0iTTE2IDVoLjk5TDE3IDNIN3YyaDF2N2wtMiAydjJoNXY2bDEgMSAxLTF2LTZoNXYtMmwtMi0yVjV6Ii8+DQogICAgPHBhdGggZmlsbD0ibm9uZSIgZD0iTTAgMGgyNHYyNEgweiIvPg0KPC9zdmc+);
}

.meta-icons .archived {
  background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjwhLS0gR2VuZXJhdG9yOiBBZG9iZSBJbGx1c3RyYXRvciAxOC4wLjAsIFNWRyBFeHBvcnQgUGx1Zy1JbiAuIFNWRyBWZXJzaW9uOiA2LjAwIEJ1aWxkIDApICAtLT4KPCFET0NUWVBFIHN2ZyAgUFVCTElDICctLy9XM0MvL0RURCBTVkcgMS4xLy9FTicgICdodHRwOi8vd3d3LnczLm9yZy9HcmFwaGljcy9TVkcvMS4xL0RURC9zdmcxMS5kdGQnPgo8c3ZnIGlkPSJMYXllcl8xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbDpzcGFjZT0icHJlc2VydmUiIHZpZXdCb3g9IjAgMCAxOCAxOCIgdmVyc2lvbj0iMS4xIiB5PSIwcHgiIHg9IjBweCIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDE4IDE4Ij4KPHBhdGggZD0ibTE2LjYgM2wtMS4yLTEuNWMtMC4yLTAuMy0wLjYtMC41LTEtMC41aC0xMC43Yy0wLjQgMC0wLjggMC4yLTEgMC41bC0xLjMgMS41Yy0wLjIgMC4zLTAuNCAwLjctMC40IDEuMXYxMS4xYzAgMSAwLjggMS44IDEuOCAxLjhoMTIuNGMxIDAgMS44LTAuOCAxLjgtMS44di0xMS4xYzAtMC40LTAuMi0wLjgtMC40LTEuMXptLTcuNiAxMC45bC00LjktNC45aDMuMXYtMS44aDMuNnYxLjhoMy4xbC00LjkgNC45em0tNi4xLTExLjFsMC43LTAuOWgxMC43bDAuOCAwLjloLTEyLjJ6Ii8+Cjwvc3ZnPgo=);
}

.meta-icons .trashed {
  background-image: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjE4cHgiIHdpZHRoPSIxOHB4IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0OCA0OCIgZmlsbD0iIzAwMDAwMCI+DQogPHBhdGggZD0ibTEyIDM4YzAgMi4yMSAxLjc5IDQgNCA0aDE2YzIuMjEgMCA0LTEuNzkgNC00di0yNGgtMjR2MjR6bTI2LTMwaC03bC0yLTJoLTEwbC0yIDJoLTd2NGgyOHYtNHoiLz4NCiA8cGF0aCBkPSJtMCAwaDQ4djQ4aC00OHoiIGZpbGw9Im5vbmUiLz4NCjwvc3ZnPg==);
}

.checked {
  text-decoration: line-through;
}

.RED {
  background-color: rgb(255, 109, 63) !important;
}
.ORANGE {
  background-color: rgb(255, 155, 0) !important;
}
.YELLOW {
  background-color: rgb(255, 218, 0) !important;
}
.GREEN {
  background-color: rgb(149, 214, 65) !important;
}
.TEAL {
  background-color: rgb(28, 232, 181) !important;
}
.BLUE {
  background-color: rgb(63, 195, 255) !important;
}
.GRAY {
  background-color: rgb(184, 196, 201) !important;
}

/* go/keep-more-colors-eng */
.CERULEAN {
  background-color: rgb(130, 177, 255) !important;
}
.PURPLE {
  background-color: rgb(179, 136, 255) !important;
}
.PINK {
  background-color: rgb(248, 187, 208) !important;
}
.BROWN {
  background-color: rgb(215, 204, 200) !important;
}

      </style></head>
<body><div class="note RED"><div class="heading"><div class="meta-icons">

</div>
Feb 17, 2017, 1:00:29 PM</div>
<div class="title">GPU Software</div>
<div class="content">https://devblogs.nvidia.com/parallelforall/mixed-precision-programming-cuda-8/<br><br>cuDNN - primitives. v5.0 has FP16 support<br>Tensorrt - inference engine; v1 = FP16 support, v2 (roadmap) = INT8 support<br>cuBLAS = linear algebra<br>cuFFT = fast fourier library in cuda<br>cuSPARSE = sparse matrix library<br><br>https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_pref01.html<br><br>GPU optimized libs: https://developer.nvidia.com/gpu-accelerated-libraries<br>* AmgX: https://developer.nvidia.com/amgx<br>* cuDNN: https://developer.nvidia.com/cuDNN<br>* cuFFT: https://developer.nvidia.com/cufft<br>* IndeX: https://developer.nvidia.com/index<br>* nvGRAPH: https://developer.nvidia.com/nvgraph<br>* TensorRT: https://developer.nvidia.com/tensorrt<br>* NPP: https://developer.nvidia.com/npp<br>* FFmpeg: https://developer.nvidia.com/ffmpeg<br>* CHOLMOD<br>* CULA<br>* MAGMA<br>* IMSL<br>* cuSOLVER<br>* cuSPARSE<br>* cuBLAS<br>* ArrayFire<br>* cuRAND<br>* CUDA Math<br>* Thrust<br>* NVBIO<br>* Video Codec SDK<br>* HiPLAR<br>* OpenCV: https://developer.nvidia.com/opencv<br>* GPP<br>* Paralution<br>* Triton SDK: https://developer.nvidia.com/triton-ocean-sdk<br><br><br><br>supercomputing:<br>http://www.nvidia.com/object/tesla-supercomputing-solutions.html<br><br>numerical analysis:<br>https://developer.nvidia.com/numerical-analysis-tools<br><br>languages/APIs: https://developer.nvidia.com/language-solutions<br>* CUDA Toolkit: https://developer.nvidia.com/cuda-toolkit<br>* OpenACC: https://developer.nvidia.com/openacc<br>* PGI Accelerator: https://developer.nvidia.com/pgi-accelerator-fortran-and-c-compilers<br>* PGI C++ compiler: https://developer.nvidia.com/pgi-cuda-cc-x86<br>* CUDA Fortran: https://developer.nvidia.com/cuda-fortran<br>* Anaconda Accelerate: https://developer.nvidia.com/anaconda-accelerate<br>* PyCUDA: https://developer.nvidia.com/cuda/pycuda<br>* Altimesh Hybridizer: https://developer.nvidia.com/altimesh-hybridizer<br>* OpenCL: https://developer.nvidia.com/opencl<br>* Alea GPU: https://developer.nvidia.com/alea-gpu<br><br>performance analysis: https://developer.nvidia.com/performance-analysis-tools<br>* Nsight: http://www.nvidia.com/nsight<br>* Visual Profiler: https://developer.nvidia.com/nvidia-visual-profiler<br>* TAU: https://developer.nvidia.com/tau-performance-system<br>* VampirTrace: https://developer.nvidia.com/vampirtrace<br>* CUDA-PAPI: https://developer.nvidia.com/papi-cuda-component<br>* CUDA-CUPTI: https://developer.nvidia.com/cuda-profiling-tools-interface<br>* CUDA C Best Practices: https://developer.nvidia.com/nvidia-gpu-computing-documentation#cudacbestpractices<br><br>debugging tools: https://developer.nvidia.com/debugging-solutions<br>* Allinea DDT: https://developer.nvidia.com/allinea-ddt<br>* TotalView: https://developer.nvidia.com/totalview-debugger<br>* Nsight: http://www.nvidia.com/nsight<br>* CUDA-GDB: https://developer.nvidia.com/cuda-gdb<br>* CUDA-Memcheck: https://developer.nvidia.com/CUDA-MEMCHECK<br><br>&quot;key technologies&quot;: https://developer.nvidia.com/key-technologies<br>* https://developer.nvidia.com/jetson-tk1<br>* https://developer.nvidia.com/gpudirect<br>* https://developer.nvidia.com/cuda-llvm-compiler<br>* https://developer.nvidia.com/mpi-solutions-gpus<br>* https://developer.nvidia.com/digits<br>* <br><br>GPU optimized web svcs: https://developer.nvidia.com/gpu-accelerated-web-services<br>* Image Compute Engine (ICE)<br>* GPU Rest Engine (GRE)<br><br>Cluster mgmt:<br>https://developer.nvidia.com/cluster-management<br>* Bright Cluster Mgr<br>* Ganglia<br>* StackIQ<br>* GPU Deployment Kit<br>* IBM Platform LSF<br>* PBS Professional<br>* Moab Cluster Suite<br>* Grid Engine<br>* Torque<br>* SLURM</div>
<div class="chips"><span class="chip annotation WEBLINK"><a title="Managing your Cluster and Scheduling jobs on your GPU Cluster can be simple and intuitive with industry leading solutions now with NVIDIA GPU support." href="https://developer.nvidia.com/cluster-management"><span class="chip-icon"></span>
<span class="annotation-text">Cluster Management</span></a>
</span> <span class="chip annotation WEBLINK"><a title="CUDA Toolkit Documentation v8.0. Release Notes: The Release Notes for the CUDA Toolkit. EULA: The End User License Agreements for the NVIDIA CUDA Toolkit, the NVIDIA CUDA Samples, the NVIDIA Display Driver, and NVIDIA NSight (Visual Studio Edition). Installation Guides. Quick Start Guide ..." href="http://docs.nvidia.com/cuda/index.html"><span class="chip-icon"></span>
<span class="annotation-text">CUDA Toolkit Documentation</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Millions of people now share photos, video, and music or spoken words on the web daily. GPU powered micro services can process this data quickly to deliver great visual experiences and intelligent capabilities based on deep learning." href="https://developer.nvidia.com/gpu-accelerated-web-services"><span class="chip-icon"></span>
<span class="annotation-text">GPU-Accelerated Web Services</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The NVIDIA CUDA Fast Fourier Transform library (cuFFT) provides a simple interface for computing FFTs up to 10x faster.  By using hundreds of processor cores inside NVIDIA GPUs, cuFFT delivers the floating&#8208;point performance of a GPU without having to develop your own custom GPU FFT implementation." href="https://developer.nvidia.com/cufft"><span class="chip-icon"></span>
<span class="annotation-text">cuFFT</span></a>
</span> <span class="chip annotation WEBLINK"><a title="PyCUDA lets you access Nvidia&#39;s CUDA parallel computation API from Python." href="https://developer.nvidia.com/pycuda"><span class="chip-icon"></span>
<span class="annotation-text">PyCUDA</span></a>
</span> <span class="chip annotation WEBLINK"><a title="3D Visualization for Discovery and Exploration      NVIDIA IndeX&trade; is a commercial SDK that leverages GPU clusters for scalable, real-time, visualization and computing of multi-valued volumetric data together with embedded geometry data." href="https://developer.nvidia.com/index"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA IndeX</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Triton provides real-time visual simulation of the ocean and bodies of water for games, simulation, and training applications. Through the use of CUDA and cuFFT, Triton simulates thousands of waves at once at hundreds of frames per second, providing realistic ocean and water in virtual environments. In addition to 3D water and waves, Triton also renders ship wakes and spray effects consistent with any wind conditions or Beaufort scale specified." href="https://developer.nvidia.com/triton-ocean-sdk"><span class="chip-icon"></span>
<span class="annotation-text">Triton Ocean SDK</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The NVIDIA CUDA Profiling Tools Interface (CUPTI) provides performance analysis tools with detailed information about how applications are using the GPUs in a system. CUPTI provides two simple yet powerful mechanisms that allow performance analysis tools such as the NVIDIA Visual Profiler, TAU and Vampir Trace to understand the inner workings of an application and deliver valuable insights to developers." href="https://developer.nvidia.com/cuda-profiling-tools-interface"><span class="chip-icon"></span>
<span class="annotation-text">CUDA Profiling Tools Interface</span></a>
</span> <span class="chip annotation WEBLINK"><a title="CUDA Toolkit Provides a comprehensive environment for C/C++ developers building GPU-accelerated applications." href="https://developer.nvidia.com/language-solutions"><span class="chip-icon"></span>
<span class="annotation-text">Language Solutions</span></a>
</span> <span class="chip annotation WEBLINK"><a title="NVIDIA&reg; Nsight&trade;" href="https://developer.nvidia.com/performance-analysis-tools"><span class="chip-icon"></span>
<span class="annotation-text">Performance Analysis Tools</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Matlab  by Mathworks, has native support for CUDA in the Parallel Computing Toolbox. Enjoy GPU acceleration without having to write any CUDA Kernels." href="https://developer.nvidia.com/numerical-analysis-tools"><span class="chip-icon"></span>
<span class="annotation-text">Numerical Analysis Tools</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/altimesh-hybridizer"><span class="chip-icon"></span>
<span class="annotation-text">Altimesh Hybridizer</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Description TotalView is a dynamic source code and memory debugger for C, C++ and Fortran applications. TotalView for CUDA allows Linux X86-64 users to debug both the CPU and GPU code in CUDA applications, using familiar TotalView GUI methods." href="https://developer.nvidia.com/totalview-debugger"><span class="chip-icon"></span>
<span class="annotation-text">TotalView Debugger</span></a>
</span> <span class="chip annotation WEBLINK"><a title="NVIDIA&reg; Nsight&trade;, in combination with Visual Studio, allows you to leverage the CPU for parallel tasks and the GPU for massively parallel computing." href="http://www.nvidia.com/object/nsight.html"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA Nsight | NVIDIA</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Whether you are exploring mountains of geological data, researching solutions to complex scientific problems, or racing to model fast-moving financial markets, you need a computing platform that delivers the highest throughput and lowest latency possible. GPU-accelerated clusters and workstations are widely recognized for providing the tremendous horsepower required by compute-intensive workloads. Compute-intensive applications can provide even faster results with  NVIDIA GPUDirect&trade;." href="https://developer.nvidia.com/gpudirect"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA GPUDirect</span></a>
</span> <span class="chip annotation WEBLINK"><a title="OpenCL&trade; (Open Computing Language) is a low-level API for heterogeneous computing that runs on CUDA-powered GPUs. Using the OpenCL API, developers can launch compute kernels written using a limited subset of the C programming language on a GPU. OpenCL support is included in the latest NVIDIA GPU drivers, available at www.nvidia.com/drivers" href="https://developer.nvidia.com/opencl"><span class="chip-icon"></span>
<span class="annotation-text">OpenCL</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/vampirtrace"><span class="chip-icon"></span>
<span class="annotation-text">VampirTrace</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Using PGI Accelerator compilers, programmers can accelerate applications on x64+GPU platforms by adding OpenMP-like compiler directives to existing high-level standard-compliant Fortran,C and C++ programs and then recompiling with appropriate compiler options. Sample Fortran matrix multiplication loop, with directives:" href="https://developer.nvidia.com/pgi-accelerator-fortran-and-c-compilers"><span class="chip-icon"></span>
<span class="annotation-text">PGI Accelerator Fortran,C and C++ Compilers with OpenACC</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/     Jetson Embedded Hardware" href="https://developer.nvidia.com/embedded/develop/hardware"><span class="chip-icon"></span>
<span class="annotation-text">Embedded Hardware</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Allinea DDT Provides application developers with a single tool that can debug hybrid MPI, OpenMP, CUDA and OpenACC applications on a single workstation or GPU cluster." href="https://developer.nvidia.com/debugging-solutions"><span class="chip-icon"></span>
<span class="annotation-text">Debugging Solutions</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/tensorrt"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA TensorRT</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/digits"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA DIGITS</span></a>
</span> <span class="chip annotation WEBLINK"><a title="" href="https://developer.nvidia.com/cuda-toolkit"><span class="chip-icon"></span>
<span class="annotation-text">CUDA Toolkit</span></a>
</span> <span class="chip annotation WEBLINK"><a title="In the practice of software development, programmers learn early and often the importance of using the right tool for the job. This is especially important when it comes to numerical computing, where tradeoffs between precision, accuracy, and performance make it essential to choose the best representations for data. With the introduction of the Pascal GPU &hellip;" href="https://devblogs.nvidia.com/parallelforall/mixed-precision-programming-cuda-8/"><span class="chip-icon"></span>
<span class="annotation-text">Mixed-Precision Programming with CUDA 8 | Parallel Forall</span></a>
</span> <span class="chip annotation WEBLINK"><a title="What is OpenCV? OpenCV is the leading open source library for computer vision, image processing and machine learning, and now features GPU acceleration for real-time operation." href="https://developer.nvidia.com/opencv"><span class="chip-icon"></span>
<span class="annotation-text">OpenCV</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/cuda-gdb"><span class="chip-icon"></span>
<span class="annotation-text">CUDA-GDB</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/nvidia-visual-profiler"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA Visual Profiler</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The PGI CUDA C compiler for x86 platforms allows developers using CUDA to compile and optimize their CUDA applications to run on x86-based workstations, servers and clusters with or without an NVIDIA GPU accelerator.  When run on x86-based systems without a GPU, PGI CUDA C applications uses multiple cores and the streaming SIMD (Single Instruction Multiple Data) capabilities of Intel and AMD CPUs for parallel execution. With PGI CUDA C compilers, CUDA developers now can have a common code path for both NVIDIA GPU and x86 platform." href="https://developer.nvidia.com/pgi-cuda-cc-x86"><span class="chip-icon"></span>
<span class="annotation-text">PGI CUDA C/C++ for x86</span></a>
</span> <span class="chip annotation WEBLINK"><a title="MPI (Message Passing Interface) is a standardized and portable API for communicating data via messages (both point-to-point &amp; collective) between distributed processes. MPI is frequently used in HPC to build applications that can scale on multi-node computer clusters. In most MPI implementations, library routines are directly callable from C, C++, and Fortran, as well as other languages able to interface with such libraries" href="https://developer.nvidia.com/mpi-solutions-gpus"><span class="chip-icon"></span>
<span class="annotation-text">MPI Solutions for GPUs</span></a>
</span> <span class="chip annotation WEBLINK"><a title="*/" href="https://developer.nvidia.com/cuda-memcheck"><span class="chip-icon"></span>
<span class="annotation-text">CUDA-MEMCHECK</span></a>
</span> <span class="chip annotation WEBLINK"><a title="GPU-accelerated video processing integrated into the most popular open-source multimedia tools.    FFmpeg and libav are among the most popular open-source multimedia manipulation tools with a library of plugins that can be applied to various parts of the audio and video processing pipelines and have achieved wide adoption across the world." href="https://developer.nvidia.com/ffmpeg"><span class="chip-icon"></span>
<span class="annotation-text">FFmpeg / libav</span></a>
</span> <span class="chip annotation WEBLINK"><a title="AmgX provides a simple path to accelerated core solver technology on NVIDIA GPUs. AmgX provides up to 10x acceleration to the computationally intense linear solver portion of simulations, and is especially well suited for implicit unstructured methods. It is a high performance, state-of-the-art library and includes a flexible solver composition system that allows a user to easily construct complex nested solvers and preconditioners." href="https://developer.nvidia.com/amgx"><span class="chip-icon"></span>
<span class="annotation-text">AmgX</span></a>
</span> <span class="chip annotation WEBLINK"><a title="" href="https://developer.nvidia.com/openacc"><span class="chip-icon"></span>
<span class="annotation-text">OpenACC: More Science Less Programming</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Anaconda Accelerate opens up the full capabilities of your GPU or multi-core processor to the Python programming language. Common operations like linear algebra, random-number generation, and Fourier transforms run faster, and take advantage of multiple cores. Continuum&rsquo;s revolutionary Python-to-GPU compiler, NumbaPro, compiles easy-to-read Python code to many-core and GPU architectures." href="https://developer.nvidia.com/anaconda-accelerate"><span class="chip-icon"></span>
<span class="annotation-text">Anaconda Accelerate</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Allinea DDT - part of the Allinea Forge toolsuite for high performance software - is an intuitive graphical debugger that works at the scale you do. Supporting the latest toolkits from NVIDIA, Allinea DDT provides one of the most comprehensive debuggers of CPU and GPU applications available." href="https://developer.nvidia.com/allinea-ddt"><span class="chip-icon"></span>
<span class="annotation-text">Allinea DDT</span></a>
</span> <span class="chip annotation WEBLINK"><a title="PGI CUDA Fortran is available now, providing native support of the NVIDIA&#39;s CUDA architecture. CUDA Fortran is supported on Linux, Mac OS X and Windows.  Fortran is a key programming language used by high performance computing developers. It is the language of choice in many application domains including computational fluid dynamics (including weather and ocean modeling), finite-element analysis, molecular dynamics, and quantum chemistry." href="https://developer.nvidia.com/cuda-fortran"><span class="chip-icon"></span>
<span class="annotation-text">CUDA FORTRAN</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The NVIDIA Performance Primitives library (NPP) is a collection of GPU-accelerated image, video, and signal processing functions that deliver 5x to 10x faster performance than comparable CPU-only implementations. Using NPP, developers can take advantage of over 1900 image processing and  approx 600 signal processing primitives to achieve significant improvements in application performance in a matter of hours." href="https://developer.nvidia.com/npp"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA Performance Primitives</span></a>
</span> <span class="chip annotation WEBLINK"><a title="TAU Performance System&reg; is a profiling and tracing toolkit for performance analysis of hybrid parallel programs written in CUDA C, CUDA C++, OpenCL or using pyCUDA or OpenACC.  TAU gathers performance information of GPU computations and integrates it with other application performance data, through instrumentation of functions, methods, basic blocks, and statements to capture a performance picture of the resulting application execution." href="https://developer.nvidia.com/tau-performance-system"><span class="chip-icon"></span>
<span class="annotation-text">TAU Performance System</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The PAPI CUDA Component is a hardware performance counter measurement technology for the NVIDIA CUDA platform which provides access to the hardware counters inside the GPU. PAPI CUDA is based on CUDA Performance Tools Interface (CUPTI) support in the NVIDIA driver library. In any environment where the CUPTI-enabled driver is installed, the PAPI CUDA Component can provide detailed performance counter information regarding the execution of GPU kernels." href="https://developer.nvidia.com/papi-cuda-component"><span class="chip-icon"></span>
<span class="annotation-text">PAPI CUDA Component</span></a>
</span> <span class="chip annotation WEBLINK"><a title="" href="https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_pref01.html"><span class="chip-icon"></span>
<span class="annotation-text">GPU Gems</span></a>
</span> <span class="chip annotation WEBLINK"><a title="" href="https://developer.nvidia.com/cudnn"><span class="chip-icon"></span>
<span class="annotation-text">NVIDIA cuDNN</span></a>
</span> <span class="chip annotation WEBLINK"><a title="The NVIDIA Graph Analytics library (nvGRAPH) comprises of parallel algorithms for high performance analytics on graphs with up to 2 billion edges. nvGRAPH makes it possible to build interactive and high throughput graph analytics applications. nvGRAPH supports three widely-used algorithms: Page Rank is most famously used in search engines, and also used in social network analysis, recommendation systems, and for novel uses in natural science when studying the relationship between proteins and in ecological networks." href="https://developer.nvidia.com/nvgraph"><span class="chip-icon"></span>
<span class="annotation-text">nvGRAPH</span></a>
</span> <span class="chip annotation WEBLINK"><a title="GPU-Accelerated libraries provide highly-optimized algorithms and functions you can incorporate into your applications, with minimal changes to your existing code. Many support drop-in compatibilty to replace industry standard CPU-only libraries such as MKL, IPP, FFTW and widely-used libraries. Some also feature automatic multi-GPU performance scaling." href="https://developer.nvidia.com/gpu-accelerated-libraries"><span class="chip-icon"></span>
<span class="annotation-text">GPU-Accelerated Libraries</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Personal supercomputers powered with Tesla GPUs run applications 10x faster and accelerate your scientific research. Industry relevant case studies, specs, and more." href="http://www.nvidia.com/object/tesla-supercomputing-solutions.html"><span class="chip-icon"></span>
<span class="annotation-text">High Performance Computing (HPC) and Supercomputing | NVIDIA Tesla | NVIDIA</span></a>
</span> <span class="chip annotation WEBLINK"><a title="To cope with the fragmented GPU computing landscape in terms of hardware and platform diversity, software companies increasingly rely on the .NET framework as a strategic cross platform technology for their CPU and GPU codebase." href="https://developer.nvidia.com/alea-gpu"><span class="chip-icon"></span>
<span class="annotation-text">Alea GPU</span></a>
</span> <span class="chip annotation WEBLINK"><a title="NVIDIA&#39;s CUDA Compiler (NVCC) is based on the widely used LLVM open source compiler infrastructure. Developers can create or extend programming languages with support for GPU acceleration using the NVIDIA Compiler SDK." href="https://developer.nvidia.com/cuda-llvm-compiler"><span class="chip-icon"></span>
<span class="annotation-text">CUDA LLVM Compiler</span></a>
</span> <span class="chip annotation WEBLINK"><a title="Jetson TK1 Development Kit" href="https://developer.nvidia.com/key-technologies"><span class="chip-icon"></span>
<span class="annotation-text">Key Technologies</span></a>
</span>
</div>

</div></body></html>