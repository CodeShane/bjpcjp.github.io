---
layout: post
title:  "Goodfellow book contents"
date:   2019-06-08 0:0:0 -0500
categories: notes
---

<div style="columns: 3;">
<p><strong><a href="/pdfs/dl-goodfellow/intro.pdf">
    Introduction</a></strong></p>

<p><strong><a href="/pdfs/dl-goodfellow/linear_algebra-DLgoodfellow.pdf">
    Linear Algebra</a></strong>
    <div style="border: 1px solid black; padding: 0.5em;">
        Scalars, Vectors, Matrics, Tensors<br>
        Vector & Matrix Multiplication<br>
        Identity & Inverse Matrices<br>
        Linear Dependence<br>
        Span<br>
        Norms<br>
        Other Special Vectors & Matrices<br>
        Eigendecomposition<br>
        Singular Value Decomposition<br>
        Moore-Penrose Pseudoinverse<br>
        Trace Operator<br>
        Determinants<br>
        Principal Component Analysis
    </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/probability-DLgoodfellow.pdf">
        Probability</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Why?<br>
            Random Variables<br>
            Distributions<br>
            Marginal Probability<br>
            Conditional Probability<br>
            Chain Rule<br>
            (Conditional) Independence<br>
            Expectation, Variance, Covariance<br>
            Common Distributions<br>
            Useful Properties<br>
            Bayes' Rule<br>
            Continuous Variables - Details<br>
            Information Theory<br>
            Structured Models
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/numerical-computation-DLgoodfellow.pdf">
        Math</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Overflow, Underflow<br>
            (Poor) Conditioning<br>
            Gradients<br>
            Constrained Optimization<br>
            Ex: Linear Least Squares
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/machine-learning-basics-DLgoodfellow.pdf">
        Machine Learning Basics</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Learning Algorithms<br>
            Capacity, Overfit, Underfit<br>
            Hyperparameters<br>
            Validation Sets<br>
            Estimators, Bias, Variance<br>
            Max Likelihood Estimation (MLE)<br>
            Bayes Statistics<br>
            Supervised Learning<br>
            Unsupervised Learning<br>
            Stochastic Gradient Descent (SGD)<br>
            Building an Algorithm<br>
            Challenges
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/deep-feedforward-nets-DLgoodfellow.pdf">
        Deep Feedforward Nets</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Ex: XOR<br>
            Gradient-based Learning<br>
            Hidden Units<br>
            Architecture Design<br>
            Back-Propagation & Related Algos<br>
            Historical Notes
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/regularization-DLgoodfellow.pdf">
        Regularization</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Parameter Norm Penalties<br>
            Penalties as Constrained Optimization<br>
            Under-Constrained Problems<br>
            Dataset Augmentation<br>
            Noise Robustness<br>
            Semi-Supervised Learning<br>
            Multi-task Learning<br>
            Early Stopping<br>
            Parameter Tying/Sharing<br>
            Sparse Representations<br>
            Ensemble Methods (Bagging, etc)<br>
            Dropout<br>
            Adversarial Training<br>
            Tangent Distance, Tangent Prop, Manifold Tangent Classifier
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/optimization-DLgoodfellow.pdf">
        Optimization</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Learning vs Pure Optimization<br>
            Challenges<br>
            Basic Algos<br>
            Parameter Setup<br>
            Adaptive Learning Rates<br>
            Approximate 2nd-Order Methods<br>
            Meta-Algorithms
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/convolutional-nets-DLgoodfellow.pdf">
        Convolutional Nets</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Convolution<br>
            Motivation<br>
            Pooling<br>
            Infinitely Strong Prior<br>
            Variants<br>
            Structured Outputs<br>
            Data types<br>
            Efficient Algorithms<br>
            Random / Unsupervised Features<br>
            Neural Basis<br>
            Historicals
        </div></p>
    
    <p><strong><a href="/pdfs/dl-goodfellow/recurrent-recursive-nets-DLgoodfellow.pdf">
        Recurrent-Recursive Nets</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Unfolding Computational Graphs<br>
            Recurrent NNs (RNNs)<br>
            Bidirectional RNNs<br>
            Encoder-Decoder Architectures<br>
            Deep RNNs<br>
            Recursive NNs<br>
            Long-Term Dependency Challenges<br>
            Echo State Nets<br>
            Multiple Time Scale Strategies<br>
            Gated RNNs<br>
            Long-Term Dependency Optimization<br>
            Explicit Memory
        </div></p>
    
    <p><strong><a href="/pdfs/dl-goodfellow/guidelines-methodology-DLgoodfellow.pdf">
        Methodologies</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Metrics<br>
            Baseline Models<br>
            Gather More Data?<br>
            Hyperparameters<br>
            Debugging<br>
            Example: Digit Recognition
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/applications-DLgoodfellow.pdf">
        Applications</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Large-scale Deep Learning<br>
            Vision<br>
            Speech Recognition<br>
            Natural Language Processing<br>
            More
        </div></p>

    <p><strong><a href="/pdfs/dl-goodfellow/autoencoders-DLgoodfellow.pdf">
        Autoencoders (AEs)</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Undercomplete AEs<br>
            Regularized AEs<br>
            Representational Power, Layer Size, Depth<br>
            Stochastic Encoders, Decoders<br>
            Denoising AEs<br>
            Learning Manifolds with AEs<br>
            Contractive AEs<br>
            Predictive Sparse Decomposition (PSD)<br>
            Applications
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/representation-learning-DLgoodfellow.pdf">
        Representation Learning</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Greedy Layer-Wise Unsupervised Pretraining<br>
            Transfer Learning, Domain Adaptation<br>
            Semi-Supervised Causal Factor Analysis<br>
            Distributed Representation<br>
            Exponential Gains from Depth<br>
            Clues & Causes
        </div></p>
            
    <p><strong><a href="/pdfs/dl-goodfellow/structured-probabilistic-models-DLgoodfellow.pdf">
        Structured Probabilistic Models (SPMs)</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Challenges<br>
            Using Graphs<br>
            Sampling from Graphs<br>
            Advantages<br>
            Learning about Dependencies<br>
            (Approximate) Inference<br>
            Deep Learning & SPMs
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/monte-carlo-methods-DLgoodfellow.pdf">
        Monte Carlo Methods</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Sampling<br>
            Importance Sampling<br>
            Markov Chain Monte Carlo (MCMC)<br>
            Gibbs Sampling<br>
            Challenges
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/the-partition-problem-DLgoodfellow.pdf">
        The Partition Problem</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Log-Likelihood Gradient<br>
            Stochastic Max Likelihood & Contrastive Divergence<br>
            Pseudolikelihood<br>
            Score/Ratio Matching<br>
            Denoising Score Matching<br>
            Noise-Contrastive Estimation<br>
            Estimating the Partition Function
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/approximate-inference-DLgoodfellow.pdf">
        Approximate Inference</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Inference as Optimization<br>
            Expectation Maximization (EM)<br>
            MAP Inference, Sparse Coding<br>
            Variational Inference<br>
            Learned Approximate Inference<br>
        </div></p>
        
    <p><strong><a href="/pdfs/dl-goodfellow/deep-generative-models-DLgoodfellow.pdf">
        Deep Generative Models</a></strong>
        <div style="border: 1px solid black; padding: 0.5em;">
            Boltzmann Machines (BMs)<br>
            Restricted BMs<br>
            Deep Belief Nets (DBNs)<br>
            Deep BMs<br>
            BMs & Real World Data<br>
            Convolutional BMs<br>
            BMs - Structured/Sequential outputs<br>
            Other BMs<br>
            Back-Propagation thru Random Ops<br>
            Directed Generative Nets<br>
            Drawing Samples from AEs<br>
            Generative Stochastic Nets<br>
            Other Generation Schemes
        </div></p>
        
                                    
        </div>